#!/usr/bin/env bash
# ROOT_DIR_RELATIVE_TO_BIN_DIR=..

# shellcheck disable=SC2034

#####################################
# GENERATED FILE FROM https://github.com/fchastanet/bash-tools/tree/master/src/_binaries/DbImport/dbImport.sh
# DO NOT EDIT IT
#####################################

# DEPRECATED src/_includes/_header.tpl use src/_includes/_headerNoRootDir.tpl instead

# ensure that no user aliases could interfere with
# commands used in this script
unalias -a || true

# shellcheck disable=SC2034
SCRIPT_NAME=${0##*/}
REAL_SCRIPT_FILE="$(readlink -e "$(realpath "${BASH_SOURCE[0]}")")"
# shellcheck disable=SC2034
CURRENT_DIR="$(cd "$(readlink -e "${REAL_SCRIPT_FILE%/*}")" && pwd -P)"
BIN_DIR="${CURRENT_DIR}"
ROOT_DIR="$(cd "${BIN_DIR}/../../bash-dev-env/vendor/bash-tools-framework" && pwd -P)"
# shellcheck disable=SC2034
SRC_DIR="${ROOT_DIR}/src"
# shellcheck disable=SC2034
VENDOR_DIR="${ROOT_DIR}/vendor"
# shellcheck disable=SC2034
VENDOR_BIN_DIR="${ROOT_DIR}/vendor/bin"

if [[ -t 1 || -t 2 ]]; then
  # check colors applicable https://misc.flogisoft.com/bash/tip_colors_and_formatting
  export __ERROR_COLOR='\e[31m'      # Red
  export __INFO_COLOR='\e[44m'       # white on lightBlue
  export __SUCCESS_COLOR='\e[32m'    # Green
  export __WARNING_COLOR='\e[33m'    # Yellow
  export __TEST_COLOR='\e[100m'      # Light magenta
  export __TEST_ERROR_COLOR='\e[41m' # white on red
  export __SKIPPED_COLOR='\e[33m'    # Yellow
  export __HELP_COLOR='\e[7;49;33m'  # Black on Gold
  export __DEBUG_COLOR='\e[37m'      # Grey
  # Internal: reset color
  export __RESET_COLOR='\e[0m' # Reset Color
  # shellcheck disable=SC2155,SC2034
  export __HELP_EXAMPLE="$(echo -e "\e[1;30m")"
  # shellcheck disable=SC2155,SC2034
  export __HELP_TITLE="$(echo -e "\e[1;37m")"
  # shellcheck disable=SC2155,SC2034
  export __HELP_NORMAL="$(echo -e "\033[0m")"
else
  # check colors applicable https://misc.flogisoft.com/bash/tip_colors_and_formatting
  export __ERROR_COLOR=''
  export __INFO_COLOR=''
  export __SUCCESS_COLOR=''
  export __WARNING_COLOR=''
  export __SKIPPED_COLOR=''
  export __HELP_COLOR=''
  export __TEST_COLOR=''
  export __TEST_ERROR_COLOR=''
  export __DEBUG_COLOR=''
  # Internal: reset color
  export __RESET_COLOR=''
  export __HELP_EXAMPLE=''
  export __HELP_TITLE=''
  export __HELP_NORMAL=''
fi

################################################
# Temp dir management
################################################

KEEP_TEMP_FILES="${KEEP_TEMP_FILES:-0}"
export KEEP_TEMP_FILES

# PERSISTENT_TMPDIR is not deleted by traps
PERSISTENT_TMPDIR="${TMPDIR:-/tmp}/bash-framework"
export PERSISTENT_TMPDIR
mkdir -p "${PERSISTENT_TMPDIR}"

# shellcheck disable=SC2034
TMPDIR="$(mktemp -d -p "${PERSISTENT_TMPDIR:-/tmp}" -t bash-framework-$$-XXXXXX)"
export TMPDIR

# temp dir cleaning
cleanOnExit() {
  if [[ "${KEEP_TEMP_FILES:-0}" = "1" ]]; then
    Log::displayInfo "KEEP_TEMP_FILES=1 temp files kept here '${TMPDIR}'"
  elif [[ -n "${TMPDIR+xxx}" ]]; then
    Log::displayDebug "KEEP_TEMP_FILES=0 removing temp files '${TMPDIR}'"
    rm -Rf "${TMPDIR:-/tmp/fake}" >/dev/null 2>&1
  fi
}
trap cleanOnExit EXIT HUP QUIT ABRT TERM

# @see https://unix.stackexchange.com/a/386856
interruptManagement() {
  # restore SIGINT handler
  trap - INT
  # ensure that Ctrl-C is trapped by this script and not by sub process
  # report to the parent that we have indeed been interrupted
  kill -s INT "$$"
}
trap interruptManagement INT

# shellcheck disable=SC2034
((failures = 0)) || true

shopt -s expand_aliases

# Bash will remember & return the highest exit code in a chain of pipes.
# This way you can catch the error inside pipes, e.g. mysqldump | gzip
set -o pipefail
set -o errexit

# a log is generated when a command fails
set -o errtrace

# use nullglob so that (file*.php) will return an empty array if no file matches the wildcard
shopt -s nullglob

# ensure regexp are interpreted without accentuated characters
export LC_ALL=POSIX

export TERM=xterm-256color

#avoid interactive install
export DEBIAN_FRONTEND=noninteractive
export DEBCONF_NONINTERACTIVE_SEEN=true

# change display level to level argument
# if --verbose|-v option is parsed in arguments
Args::parseVerbose() {
  local verboseDisplayLevel="$1"
  declare -gx ARGS_VERBOSE=0
  shift || true
  local status=1
  while true; do
    if [[ "$1" = "--verbose" || "$1" = "-v" ]]; then
      status=0
      ARGS_VERBOSE=1
      break
    fi
    shift || break
  done
  if [[ "${status}" = "0" ]]; then
    export BASH_FRAMEWORK_DISPLAY_LEVEL=${verboseDisplayLevel}
  fi
  return "${status}"
}

# remove elements from array
# Performance1 : version taken from https://stackoverflow.com/a/59030460
# Performance2 : for multiple values to remove, prefer using Array::removeIf
Array::remove() {
  local -n arrayRemoveArray=$1
  shift || true # $@ contains elements to remove
  local -A valuesToRemoveKeys=()

  # Tag items to remove
  local del
  for del in "$@"; do valuesToRemoveKeys[${del}]=1; done

  # remove items
  local k
  for k in "${!arrayRemoveArray[@]}"; do
    if [[ -n "${valuesToRemoveKeys[${arrayRemoveArray[k]}]+xxx}" ]]; then
      unset 'arrayRemoveArray[k]'
    fi
  done

  # compaction (element re-indexing, because unset makes "holes" in array )
  arrayRemoveArray=("${arrayRemoveArray[@]}")
}

# Public: check if command specified exists or return 1
# with error and message if not
#
# **Arguments**:
# * $1 commandName on which existence must be checked
# * $2 helpIfNotExists a help command to display if the command does not exist
#
# **Exit**: code 1 if the command specified does not exist
Assert::commandExists() {
  local commandName="$1"
  local helpIfNotExists="$2"

  "${BASH_FRAMEWORK_COMMAND:-command}" -v "${commandName}" >/dev/null 2>/dev/null || {
    Log::displayError "${commandName} is not installed, please install it"
    if [[ -n "${helpIfNotExists}" ]]; then
      Log::displayInfo "${helpIfNotExists}"
    fi
    return 1
  }
  return 0
}

# Public: exits with message if current user is root
#
# **Exit**: code 1 if current user is root
Assert::expectNonRootUser() {
  if [[ "$(id -u)" = "0" ]]; then
    Log::fatal "The script must not be run as root"
  fi
}

# Public: get absolute conf file from specified conf folder deduced using these rules
#   * from absolute file (ignores <confFolder> and <extension>)
#   * relative to where script is executed (ignores <confFolder> and <extension>)
#   * from home/.bash-tools/<confFolder>
#   * from framework conf/<confFolder>
#
# **Arguments**:
# * $1 confFolder the directory name (not the path) to list
# * $2 conf file to use without extension
# * $3 the extension (sh by default)
#
# Returns absolute conf filename
Conf::getAbsoluteFile() {
  local confFolder="$1"
  local conf="$2"
  local extension="${3-.sh}"
  if [[ -n "${extension}" && "${extension:0:1}" != "." ]]; then
    extension=".${extension}"
  fi

  testAbs() {
    local result
    result="$(realpath -e "$1" 2>/dev/null)"
    # shellcheck disable=SC2181
    if [[ "$?" = "0" && -f "${result}" ]]; then
      echo "${result}"
      return 0
    fi
    return 1
  }

  # conf is absolute file (including extension)
  testAbs "${confFolder}${extension}" && return 0
  # conf is absolute file
  testAbs "${confFolder}" && return 0
  # conf is absolute file (including extension)
  testAbs "${conf}${extension}" && return 0
  # conf is absolute file
  testAbs "${conf}" && return 0

  # relative to where script is executed (including extension)
  if [[ -n "${CURRENT_DIR+xxx}" ]]; then
    testAbs "$(File::concatenatePath "${CURRENT_DIR}" "${confFolder}")/${conf}${extension}" && return 0
  fi
  # from home/.bash-tools/<confFolder>
  testAbs "$(File::concatenatePath "${HOME}/.bash-tools" "${confFolder}")/${conf}${extension}" && return 0

  if [[ -n "${ROOT_DIR+xxx}" ]]; then
    # from framework conf/<confFolder> (including extension)
    testAbs "$(File::concatenatePath "${ROOT_DIR}/conf" "${confFolder}")/${conf}${extension}" && return 0

    # from framework conf/<confFolder>
    testAbs "$(File::concatenatePath "${ROOT_DIR}/conf" "${confFolder}")/${conf}" && return 0
  fi

  # file not found
  Log::displayError "conf file '${conf}' not found"

  return 1
}

# Public: list the conf files list available in bash-tools/conf/<conf> folder
# and those overridden in ${HOME}/.bash-tools/<conf> folder
# **Arguments**:
# * $1 confFolder the directory name (not the path) to list
# * $2 the extension (sh by default)
# * $3 the indentation ('       - ' by default) can be any string compatible with sed not containing any /
#
# **Output**: list of files without extension/directory
# eg:
#       - default.local
#       - default.remote
#       - localhost-root
Conf::getMergedList() {
  local confFolder="$1"
  local extension="${2:-sh}"
  local indentStr="${3:-       - }"

  local DEFAULT_CONF_DIR="${ROOT_DIR}/conf/${confFolder}"
  local HOME_CONF_DIR="${HOME}/.bash-tools/${confFolder}"

  (
    if [[ -d "${DEFAULT_CONF_DIR}" ]]; then
      Conf::list "${DEFAULT_CONF_DIR}" "" "${extension}" "-type f" "${indentStr}"
    fi
    if [[ -d "${HOME_CONF_DIR}" ]]; then
      Conf::list "${HOME_CONF_DIR}" "" "${extension}" "-type f" "${indentStr}"
    fi
  ) | sort | uniq
}

# Public: dump db limited to optional table list
#
# **Arguments**:
# * $1 (passed by reference) database instance to use
# * $2 the db to dump
# * _$3(optional)_ string containing table list
#       (can be empty string in order to specify additional options)
# * _$4(optional)_ ... additional dump options
#
# **Returns**: mysqldump command status code
Database::dump() {
  # shellcheck disable=SC2178
  local -n instanceDump=$1
  shift || true
  local db="$1"
  shift || true
  # optional table list
  local optionalTableList=""
  if [[ -n "${1+x}" ]]; then
    optionalTableList="$1"
    shift || true
  fi
  local -a dumpAdditionalOptions=()
  local -a mysqlCommand=()

  # additional options
  if [[ -n "${1+x}" ]]; then
    dumpAdditionalOptions=("$@")
  fi

  mysqlCommand+=(mysqldump)
  mysqlCommand+=("--defaults-extra-file=${instanceDump['AUTH_FILE']}")
  IFS=' ' read -r -a dumpOptions <<<"${instanceDump['DUMP_OPTIONS']}"
  mysqlCommand+=("${dumpOptions[@]}")
  mysqlCommand+=("${dumpAdditionalOptions[@]}")
  mysqlCommand+=("${db}")
  # shellcheck disable=SC2206
  mysqlCommand+=(${optionalTableList})

  Log::displayDebug "execute command: '${mysqlCommand[*]}'"
  "${mysqlCommand[@]}"
  return $?
}

# Public: check if given database exists
#
# **Arguments**:
# * $1 (passed by reference) database instance to use
# * $2 database name
Database::ifDbExists() {
  local -n instanceIfDbExists=$1
  local dbName result
  dbName="$2"
  local -a mysqlCommand=()

  mysqlCommand+=(mysqlshow)
  mysqlCommand+=("--defaults-extra-file=${instanceIfDbExists['AUTH_FILE']}")
  # shellcheck disable=SC2206
  mysqlCommand+=(${instanceIfDbExists['SSL_OPTIONS']})
  mysqlCommand+=("${dbName}")
  Log::displayDebug "execute command: '${mysqlCommand[*]}'"
  result="$(MSYS_NO_PATHCONV=1 "${mysqlCommand[@]}" 2>/dev/null | grep '^Database: ' | grep -o "${dbName}")"
  [[ "${result}" = "${dbName}" ]]
}

# Public: create a new db instance
#
# **Arguments**:
# * $1 - (passed by reference) database instance to create
# * $2 - dsn profile - load the dsn.env profile
#     absolute file is deduced using rules defined in Conf::getAbsoluteFile
#
# **Example:**
# ```shell
# declare -Agx dbInstance
# Database::newInstance dbInstance "default.local"
# ```
#
# Returns immediately if the instance is already initialized
Database::newInstance() {
  local -n instanceNewInstance=$1
  local dsn="$2"
  local DSN_FILE

  if [[ -v instanceNewInstance['INITIALIZED'] && "${instanceNewInstance['INITIALIZED']:-0}" == "1" ]]; then
    return
  fi

  # final auth file generated from dns file
  instanceNewInstance['AUTH_FILE']=""
  instanceNewInstance['DSN_FILE']=""

  # check dsn file
  DSN_FILE="$(Conf::getAbsoluteFile "dsn" "${dsn}" "env")" || return 1
  Database::checkDsnFile "${DSN_FILE}" || return 1
  instanceNewInstance['DSN_FILE']="${DSN_FILE}"

  # shellcheck source=/src/Database/testsData/dsn_valid.env
  source "${instanceNewInstance['DSN_FILE']}"

  instanceNewInstance['USER']="${USER}"
  instanceNewInstance['PASSWORD']="${PASSWORD}"
  instanceNewInstance['HOSTNAME']="${HOSTNAME}"
  instanceNewInstance['PORT']="${PORT}"

  # generate authFile for easy authentication
  instanceNewInstance['AUTH_FILE']=$(mktemp -p "${TMPDIR:-/tmp}" -t "mysql.XXXXXXXXXXXX")
  (
    echo "[client]"
    echo "user = ${USER}"
    echo "password = ${PASSWORD}"
    echo "host = ${HOSTNAME}"
    echo "port = ${PORT}"
  ) >"${instanceNewInstance['AUTH_FILE']}"

  # some of those values can be overridden using the dsn file
  # SKIP_COLUMN_NAMES enabled by default
  instanceNewInstance['SKIP_COLUMN_NAMES']="${SKIP_COLUMN_NAMES:-1}"
  instanceNewInstance['SSL_OPTIONS']="${MYSQL_SSL_OPTIONS:---ssl-mode=DISABLED}"
  instanceNewInstance['QUERY_OPTIONS']="${MYSQL_QUERY_OPTIONS:---batch --raw --default-character-set=utf8}"
  instanceNewInstance['DUMP_OPTIONS']="${MYSQL_DUMP_OPTIONS:---default-character-set=utf8 --compress --hex-blob --routines --triggers --single-transaction --set-gtid-purged=OFF --column-statistics=0 ${instanceNewInstance['SSL_OPTIONS']}}"
  instanceNewInstance['DB_IMPORT_OPTIONS']="${DB_IMPORT_OPTIONS:---connect-timeout=5 --batch --raw --default-character-set=utf8}"

  instanceNewInstance['INITIALIZED']=1
}

# Public: mysql query on a given db
#
# **Arguments**:
# * $1 (passed by reference) database instance to use
# * $2 sql query to execute.
#    if not provided or empty, the command can be piped (eg: cat file.sql | Database::query ...)
# * _$3 (optional)_ the db name
#
# **Returns**: mysql command status code
Database::query() {
  local -n instanceQuery=$1
  local -a mysqlCommand=()

  mysqlCommand+=(mysql)
  mysqlCommand+=("--defaults-extra-file=${instanceQuery['AUTH_FILE']}")
  IFS=' ' read -r -a queryOptions <<<"${instanceQuery['QUERY_OPTIONS']}"
  mysqlCommand+=("${queryOptions[@]}")
  if [[ "${instanceQuery['SKIP_COLUMN_NAMES']}" = "1" ]]; then
    mysqlCommand+=("-s" "--skip-column-names")
  fi
  # add optional db name
  if [[ -n "${3+x}" ]]; then
    mysqlCommand+=("$3")
  fi
  # add optional sql query
  if [[ -n "${2+x}" && -n "$2" ]]; then
    if [[ ! -f "$2" ]]; then
      mysqlCommand+=("-e")
      mysqlCommand+=("$2")
    fi
  fi
  Log::displayDebug "$(printf "execute command: '%s'" "${mysqlCommand[*]}")"

  if [[ -f "$2" ]]; then
    "${mysqlCommand[@]}" <"$2"
  else
    "${mysqlCommand[@]}"
  fi
}

# Public: set the general options to use on mysql command to query the database
# Differs than setOptions in the way that these options could change each time
#
# **Arguments**:
# * $1 - (passed by reference) database instance to use
# * $2 - options list
Database::setQueryOptions() {
  local -n instanceSetQueryOptions=$1
  # shellcheck disable=SC2034
  instanceSetQueryOptions['QUERY_OPTIONS']="$2"
}

# lazy initialization
declare -g BASH_FRAMEWORK_CACHED_ENV_FILE
declare -g BASH_FRAMEWORK_DEFAULT_ENV_FILE

# load variables in order(from less specific to more specific) from :
# - ${ROOT_DIR}/src/Env/testsData/.env file
# - ${ROOT_DIR}/conf/.env file if exists
# - ~/.env file if exists
# - ~/.bash-tools/.env file if exists
# - BASH_FRAMEWORK_ENV_FILEPATH=<fullPathToEnvFile or empty if no file to be loaded>
Env::load() {
  if [[ "${BASH_FRAMEWORK_INITIALIZED:-0}" = "1" ]]; then
    return 0
  fi
  BASH_FRAMEWORK_CACHED_ENV_FILE="$(mktemp -p "${TMPDIR:-/tmp}" -t "env_vars.XXXXXXX")"
  BASH_FRAMEWORK_DEFAULT_ENV_FILE="$(mktemp -p "${TMPDIR:-/tmp}" -t "default_env_file.XXXXXXX")"
  # shellcheck source=src/Env/testsData/.env
  (
    echo "BASH_FRAMEWORK_LOG_LEVEL=${BASH_FRAMEWORK_LOG_LEVEL:-0}"
    echo "BASH_FRAMEWORK_DISPLAY_LEVEL=${BASH_FRAMEWORK_DISPLAY_LEVEL:-3}"
    echo "BASH_FRAMEWORK_LOG_FILE=${BASH_FRAMEWORK_LOG_FILE:-${ROOT_DIR}/logs/${SCRIPT_NAME}.log}"
    echo "BASH_FRAMEWORK_LOG_FILE_MAX_ROTATION=${BASH_FRAMEWORK_LOG_FILE_MAX_ROTATION:-5}"
  ) >"${BASH_FRAMEWORK_DEFAULT_ENV_FILE}"

  (
    # reset temp file
    echo >"${BASH_FRAMEWORK_CACHED_ENV_FILE}"

    # list .env files that need to be loaded
    local -a files=()
    if [[ -f "${BASH_FRAMEWORK_DEFAULT_ENV_FILE}" ]]; then
      files+=("${BASH_FRAMEWORK_DEFAULT_ENV_FILE}")
    fi
    if [[ -f "${ROOT_DIR}/conf/.env" && -r "${ROOT_DIR}/conf/.env" ]]; then
      files+=("${ROOT_DIR}/conf/.env")
    fi
    if [[ -f "${HOME}/.env" && -r "${HOME}/.env" ]]; then
      files+=("${HOME}/.env")
    fi
    local file
    for file in "$@"; do
      if [[ -f "${file}" && -r "${file}" ]]; then
        files+=("${file}")
      fi
    done
    # import custom .env file
    if [[ -n "${BASH_FRAMEWORK_ENV_FILEPATH+xxx}" ]]; then
      # load BASH_FRAMEWORK_ENV_FILEPATH
      if [[ -f "${BASH_FRAMEWORK_ENV_FILEPATH}" && -r "${BASH_FRAMEWORK_ENV_FILEPATH}" ]]; then
        files+=("${BASH_FRAMEWORK_ENV_FILEPATH}")
      else
        Log::displayWarning "env file not not found - ${BASH_FRAMEWORK_ENV_FILEPATH}"
      fi
    fi

    # add all files added as parameters
    files+=("$@")

    # source each file in order
    local file
    for file in "${files[@]}"; do
      # shellcheck source=src/Env/testsData/.env
      source "${file}" || {
        Log::displayWarning "Cannot load '${file}'"
      }
    done

    # copy only the variables to the tmp file
    local varName overrideVarName
    while IFS=$'\n' read -r varName; do
      overrideVarName="OVERRIDE_${varName}"
      if [[ -z ${!overrideVarName+xxx} ]]; then
        echo "${varName}='${!varName}'" >>"${BASH_FRAMEWORK_CACHED_ENV_FILE}"
      else
        # variable is overridden
        echo "${varName}='${!overrideVarName}'" >>"${BASH_FRAMEWORK_CACHED_ENV_FILE}"
      fi

      # using awk deduce all variables that need to be copied in tmp file
      #   from less specific file to the most
    done < <(awk -F= '!a[$1]++' "${files[@]}" | grep -v '^$\|^\s*\#' | cut -d= -f1)
  ) || exit 1

  # ensure all sourced variables will be exported
  set -o allexport

  # Finally load the temp file to make the variables available in current script
  # shellcheck source=src/Env/testsData/.env
  source "${BASH_FRAMEWORK_CACHED_ENV_FILE}"

  set +o allexport
  BASH_FRAMEWORK_INITIALIZED=1
}

Env::pathPrepend() {
  local arg
  for arg in "$@"; do
    if [[ -d "${arg}" && ":${PATH}:" != *":${arg}:"* ]]; then
      PATH="$(realpath "${arg}"):${PATH}"
    fi
  done
}

# Public: delete files older than n days
#
# **Arguments**:
# * $1 path
# * $2 modification time
#   eg: +1 match files that have been accessed at least two days ago (rounding effect)
# @see man find atime
#
# **Exit**: code 1 if the command failed
File::garbageCollect() {
  local path="$1"
  local mtime="$2"
  local maxdepth="${3:-1}"

  Log::displayInfo "Garbage collect files older than ${mtime} days in directory ${path}"
  find "${path}" -maxdepth "${maxdepth}" -type f -mtime "${mtime}" -print -delete
}

# Public: create a temp file using default TMPDIR variable
# initialized in src/_includes/_header.tpl
#
# **Arguments**:
# @param $1 {String} template (optional)
Framework::createTempFile() {
  mktemp -p "${TMPDIR:-/tmp}" -t "$1.XXXXXXXXXXXX"
}

# Public: log level off
export __LEVEL_OFF=0
# Public: log level error
export __LEVEL_ERROR=1
# Public: log level warning
export __LEVEL_WARNING=2
# Public: log level info
export __LEVEL_INFO=3
# Public: log level success
export __LEVEL_SUCCESS=3
# Public: log level debug
export __LEVEL_DEBUG=4

export __LEVEL_OFF
export __LEVEL_ERROR
export __LEVEL_WARNING
export __LEVEL_INFO
export __LEVEL_SUCCESS
export __LEVEL_DEBUG

# Display message using debug color (grey)
# @param {String} $1 message
Log::displayDebug() {
  echo -e "${__DEBUG_COLOR}DEBUG   - ${1}${__RESET_COLOR}" >&2
  Log::logDebug "$1"
}

# Display message using info color (bg light blue/fg white)
# @param {String} $1 message
Log::displayInfo() {
  local type="${2:-INFO}"
  echo -e "${__INFO_COLOR}${type}    - ${1}${__RESET_COLOR}" >&2
  Log::logInfo "$1" "${type}"
}

# Display message using error color (red) and exit immediately with error status 1
# @param {String} $1 message
Log::fatal() {
  echo -e "${__ERROR_COLOR}FATAL   - ${1}${__RESET_COLOR}" >&2
  Log::logFatal "$1"
  exit 1
}

# shellcheck disable=SC2317

Log::load() {
  # disable display methods following display level
  if ((BASH_FRAMEWORK_DISPLAY_LEVEL < __LEVEL_DEBUG)); then
    Log::displayDebug() { :; }
  fi
  if ((BASH_FRAMEWORK_DISPLAY_LEVEL < __LEVEL_INFO)); then
    Log::displayHelp() { :; }
    Log::displayInfo() { :; }
    Log::displaySkipped() { :; }
    Log::displaySuccess() { :; }
  fi
  if ((BASH_FRAMEWORK_DISPLAY_LEVEL < __LEVEL_WARNING)); then
    Log::displayWarning() { :; }
    Log::displayStatus() { :; }
  fi
  if ((BASH_FRAMEWORK_DISPLAY_LEVEL < __LEVEL_ERROR)); then
    Log::displayError() { :; }
  fi
  # disable log methods following log level
  if ((BASH_FRAMEWORK_LOG_LEVEL < __LEVEL_DEBUG)); then
    Log::logDebug() { :; }
  fi
  if ((BASH_FRAMEWORK_LOG_LEVEL < __LEVEL_INFO)); then
    Log::logHelp() { :; }
    Log::logInfo() { :; }
    Log::logSkipped() { :; }
    Log::logSuccess() { :; }
  fi
  if ((BASH_FRAMEWORK_LOG_LEVEL < __LEVEL_WARNING)); then
    Log::logWarning() { :; }
    Log::logStatus() { :; }
  fi
  if ((BASH_FRAMEWORK_LOG_LEVEL < __LEVEL_ERROR)); then
    Log::logError() { :; }
  fi

  if ((BASH_FRAMEWORK_LOG_LEVEL > __LEVEL_OFF)); then
    if [[ -z "${BASH_FRAMEWORK_LOG_FILE}" ]]; then
      BASH_FRAMEWORK_LOG_LEVEL=${__LEVEL_OFF}
      export BASH_FRAMEWORK_LOG_LEVEL
    elif [[ ! -f "${BASH_FRAMEWORK_LOG_FILE}" ]]; then
      if ! mkdir -p "$(dirname "${BASH_FRAMEWORK_LOG_FILE}")" 2>/dev/null; then
        BASH_FRAMEWORK_LOG_LEVEL=__LEVEL_OFF
        Log::displayWarning "Log dir cannot be created $(dirname "${BASH_FRAMEWORK_LOG_FILE}")"
      fi
      if ! touch --no-create "${BASH_FRAMEWORK_LOG_FILE}" 2>/dev/null; then
        BASH_FRAMEWORK_LOG_LEVEL=__LEVEL_OFF
        Log::displayWarning "Log file '${BASH_FRAMEWORK_LOG_FILE}' cannot be created"
      fi
    fi
    Log::displayInfo "Logging to file ${BASH_FRAMEWORK_LOG_FILE}"
    if ((BASH_FRAMEWORK_LOG_FILE_MAX_ROTATION > 0)); then
      Log::rotate "${BASH_FRAMEWORK_LOG_FILE}" "${BASH_FRAMEWORK_LOG_FILE_MAX_ROTATION}"
    fi
  fi
}

# Check that command version is greater than expected minimal version
# display warning if command version greater than expected minimal version
# display error if command version less than expected minimal version and exit 1
# @param {String} $1 command path
# @param {String} $2 command line parameters to launch to get command version
# @param {String} $3 expected minimal command version
# @param {String} $4 optional help message to display if command does not exist
# @return 1 if command version less than expected minimal version, 0 otherwise
# @return 2 if command does not exist
Version::checkMinimal() {
  local commandName="$1"
  local argVersion="$2"
  local minimalVersion="$3"
  local parseVersionCallback=${4:-Version::parse}
  local help="${4:-}"

  Assert::commandExists "${commandName}" "${help}" || return 2

  local version
  version="$("${commandName}" "${argVersion}" 2>&1 | ${parseVersionCallback})"

  Log::displayDebug "check ${commandName} version ${version} against minimal ${minimalVersion}"

  Version::compare "${version}" "${minimalVersion}" || {
    local result=$?
    if [[ "${result}" = "1" ]]; then
      Log::displayWarning "${commandName} version is ${version} greater than ${minimalVersion}, OK let's continue"
    elif [[ "${result}" = "2" ]]; then
      Log::displayError "${commandName} minimal version is ${minimalVersion}, your version is ${version}"
      return 1
    fi
    return 0
  }

}

# Public: list files of dir with given extension and display it as a list one by line
#
# @param {String} dir $1 the directory to list
# @param {String} prefix $2 the profile file prefix (default: "")
# @param {String} ext $3 the extension
# @param {String} findOptions $4 find options, eg: -type d
# @paramDefault {String} findOptions $4 '-type f'
# @param {String} indentStr $5 the indentation can be any string compatible with sed not containing any /
# @paramDefault {String} indentStr $5 '       - '
# @output list of files without extension/directory
# eg:
#       - default.local
#       - default.remote
#       - localhost-root
# @return 1 if directory does not exists
Conf::list() {
  local dir="$1"
  local prefix="${2:-}"
  local ext="${3}"
  local findOptions="${4--type f}"
  local indentStr="${5-       - }"

  if [[ ! -d "${dir}" ]]; then
    Log::displayError "Directory ${dir} does not exist"
  fi
  if [[ -n "${ext}" && "${ext:0:1}" != "." ]]; then
    ext=".${ext}"
  fi
  (
    # shellcheck disable=SC2086
    cd "${dir}" &&
      find . -maxdepth 1 ${findOptions} -name "${prefix}*${ext}" |
      sed -E "s#^\./${prefix}##g" |
        sed -E "s#${ext}\$##g" | sort | sed -E "s#^#${indentStr}#"
  )
}

# Internal: check if dsn file has all the mandatory variables set
# Mandatory variables are: HOSTNAME, USER, PASSWORD, PORT
#
# **Arguments**:
# * $1 - dsn absolute filename
#
# Returns 0 on valid file, 1 otherwise with log output
Database::checkDsnFile() {
  local DSN_FILENAME="$1"
  if [[ ! -f "${DSN_FILENAME}" ]]; then
    Log::displayError "dsn file ${DSN_FILENAME} not found"
    return 1
  fi

  (
    unset HOSTNAME PORT PASSWORD USER
    # shellcheck source=/src/Database/testsData/dsn_valid.env
    source "${DSN_FILENAME}"
    if [[ -z ${HOSTNAME+x} ]]; then
      Log::displayError "dsn file ${DSN_FILENAME} : HOSTNAME not provided"
      return 1
    fi
    if [[ -z "${HOSTNAME}" ]]; then
      Log::displayWarning "dsn file ${DSN_FILENAME} : HOSTNAME value not provided"
    fi
    if [[ "${HOSTNAME}" = "localhost" ]]; then
      Log::displayWarning "dsn file ${DSN_FILENAME} : check that HOSTNAME should not be 127.0.0.1 instead of localhost"
    fi
    if [[ -z "${PORT+x}" ]]; then
      Log::displayError "dsn file ${DSN_FILENAME} : PORT not provided"
      return 1
    fi
    if ! [[ ${PORT} =~ ^[0-9]+$ ]]; then
      Log::displayError "dsn file ${DSN_FILENAME} : PORT invalid"
      return 1
    fi
    if [[ -z "${USER+x}" ]]; then
      Log::displayError "dsn file ${DSN_FILENAME} : USER not provided"
      return 1
    fi
    if [[ -z "${PASSWORD+x}" ]]; then
      Log::displayError "dsn file ${DSN_FILENAME} : PASSWORD not provided"
      return 1
    fi
  )
}

File::concatenatePath() {
  local basePath="${1}"
  local subPath=${2}
  local fullPath="${basePath:+${basePath}/}${subPath}"

  realpath -m "${fullPath}" 2>/dev/null
}

# Display message using error color (red)
# @param {String} $1 message
Log::displayError() {
  echo -e "${__ERROR_COLOR}ERROR   - ${1}${__RESET_COLOR}" >&2
  Log::logError "$1"
}

# Display message using info color (bg light blue/fg white)
# @param {String} $1 message
Log::displayHelp() {
  local type="${2:-HELP}"
  echo -e "${__HELP_COLOR}${type}    - ${1}${__RESET_COLOR}" >&2
  Log::logHelp "$1" "${type}"
}

# Display message using skip color (yellow)
# @param {String} $1 message
Log::displaySkipped() {
  echo -e "${__SKIPPED_COLOR}SKIPPED - ${1}${__RESET_COLOR}" >&2
  Log::logSkipped "$1"
}

# Display message using info color (blue) but warning level
# @param {String} $1 message
Log::displayStatus() {
  local type="${2:-STATUS}"
  echo -e "${__INFO_COLOR}${type}  - ${1}${__RESET_COLOR}" >&2
  Log::logStatus "$1" "${type}"
}

# Display message using success color (bg green/fg white)
# @param {String} $1 message
Log::displaySuccess() {
  echo -e "${__SUCCESS_COLOR}SUCCESS - ${1}${__RESET_COLOR}" >&2
  Log::logSuccess "$1"
}

# Display message using warning color (yellow)
# @param {String} $1 message
Log::displayWarning() {
  echo -e "${__WARNING_COLOR}WARN    - ${1}${__RESET_COLOR}" >&2
  Log::logWarning "$1"
}

# log message to file
# @param {String} $1 message
Log::logDebug() {
  Log::logMessage "${2:-DEBUG}" "$1"
}

# log message to file
# @param {String} $1 message
Log::logError() {
  Log::logMessage "${2:-ERROR}" "$1"
}

# log message to file
# @param {String} $1 message
Log::logFatal() {
  Log::logMessage "${2:-FATAL}" "$1"
}

# log message to file
# @param {String} $1 message
Log::logHelp() {
  Log::logMessage "${2:-HELP}" "$1"
}

# log message to file
# @param {String} $1 message
Log::logInfo() {
  Log::logMessage "${2:-INFO}" "$1"
}

# log message to file
# @param {String} $1 message
Log::logSkipped() {
  Log::logMessage "${2:-SKIPPED}" "$1"
}

# log message to file
# @param {String} $1 message
Log::logStatus() {
  Log::logMessage "${2:-STATUS}" "$1"
}

# log message to file
# @param {String} $1 message
Log::logSuccess() {
  Log::logMessage "${2:-SUCCESS}" "$1"
}

# log message to file
# @param {String} $1 message
Log::logWarning() {
  Log::logMessage "${2:-WARNING}" "$1"
}

# To be called before logging in the log file
# @param {string} file $1 log file name
# @param {int} maxLogFilesCount $2 maximum number of log files
Log::rotate() {
  local file="$1"
  local maxLogFilesCount="${2:-5}"

  if [[ ! -f "${file}" ]]; then
    Log::displaySkipped "Log file ${file} doesn't exist yet"
    return 0
  fi
  for i in $(seq $((maxLogFilesCount - 1)) -1 1); do
    Log::displayInfo "Log rotation ${file}.${i} to ${file}.$((i + 1))"
    mv "${file}."{"${i}","$((i + 1))"} &>/dev/null || true
  done
  if cp "${file}" "${file}.1" &>/dev/null; then
    echo >"${file}" # reset log file
    Log::displayInfo "Log rotation ${file} to ${file}.1"
  fi
}

# @param $1 version 1
# @param $2 version 2
# @return
#   0 if equal
#   1 if version1 > version2
#   2 else
Version::compare() {
  if [[ "$1" = "$2" ]]; then
    return 0
  fi
  local IFS=.
  # shellcheck disable=2206
  local i ver1=($1) ver2=($2)
  # fill empty fields in ver1 with zeros
  for ((i = ${#ver1[@]}; i < ${#ver2[@]}; i++)); do
    ver1[i]=0
  done
  for ((i = 0; i < ${#ver1[@]}; i++)); do
    if [[ -z "${ver2[i]+unset}" ]] || [[ -z ${ver2[i]} ]]; then
      # fill empty fields in ver2 with zeros
      ver2[i]=0
    fi
    if ((10#${ver1[i]} > 10#${ver2[i]})); then
      return 1
    fi
    if ((10#${ver1[i]} < 10#${ver2[i]})); then
      return 2
    fi
  done
  return 0
}

# filter to keep only version number from a string
# @stdin the string to parse
Version::parse() {
  sed -En 's/[^0-9]*(([0-9]+\.)*[0-9]+).*/\1/p' | head -n1
}

# Internal: common log message
#
# **Arguments**:
# * $1 - message's level description
# * $2 - message
# **Output**:
# [date]|[levelMsg]|message
#
# **Examples**:
# <pre>
# 2020-01-19 19:20:21|ERROR  |log error
# 2020-01-19 19:20:21|SKIPPED|log skipped
# </pre>
Log::logMessage() {
  local levelMsg="$1"
  local msg="$2"
  local date

  if [[ -z "${BASH_FRAMEWORK_LOG_FILE}" ]]; then
    return 0
  fi
  if ((BASH_FRAMEWORK_LOG_LEVEL > __LEVEL_OFF)) || [[ "${levelMsg}" = "FATAL" ]]; then
    mkdir -p "$(dirname "${BASH_FRAMEWORK_LOG_FILE}")" || true
    if Assert::fileWritable "${BASH_FRAMEWORK_LOG_FILE}"; then
      date="$(date '+%Y-%m-%d %H:%M:%S')"
      touch "${BASH_FRAMEWORK_LOG_FILE}"
      printf "%s|%7s|%s\n" "${date}" "${levelMsg}" "${msg}" >>"${BASH_FRAMEWORK_LOG_FILE}"
    else
      echo -e "${__ERROR_COLOR}ERROR   - File ${BASH_FRAMEWORK_LOG_FILE} is not writable${__RESET_COLOR}" >&2
    fi
  fi
}

# Checks if file can be created in folder
# The file does not need to exist
Assert::fileWritable() {
  local file="$1"
  local dir

  dir="$(dirname "${file}")"

  Assert::validPath "${file}" && [[ -w "${dir}" ]]
}

# Public: check if argument is a valid linux path
#
# @param {string} path $1 path that needs to be checked
# @return 1 if path is invalid
# invalid path are those with:
# - invalid characters
# - component beginning by a - (because option)
# - not beginning with a slash
# - relative
Assert::validPath() {
  local path="$1"

  # https://regex101.com/r/afLrmM/2
  [[ "${path}" =~ ^\/$|^(\/[.a-zA-Z_0-9][.a-zA-Z_0-9-]*)+$ ]] &&
    [[ ! "${path}" =~ (\/\.\.)|(\.\.\/)|^\.$|^\.\.$ ]] # avoid relative
}

# FUNCTIONS

Env::load
export BASH_FRAMEWORK_DISPLAY_LEVEL="${__LEVEL_WARNING}"
Args::parseVerbose "${__LEVEL_INFO}" "$@" || true
declare -a args=("$@")
Array::remove args -v --verbose
set -- "${args[@]}"
Log::load

Env::pathPrepend "${VENDOR_BIN_DIR}"
Env::pathPrepend "${BIN_DIR}"

BASH_FRAMEWORK_ENV_FILEPATH=${HOME}/.bash-tools/.env
if [[ -d "${ROOT_DIR}/vendor/bash-tools-framework" ]]; then
  FRAMEWORK_DIR="$(cd "${ROOT_DIR}/vendor/bash-tools-framework" && pwd -P)"
else
  FRAMEWORK_DIR="${ROOT_DIR}/vendor/bash-tools-framework"
fi
export FRAMEWORK_DIR

Assert::expectNonRootUser

# default values
PROFILE="default"
TABLES=""
DOWNLOAD_DUMP=0
FROM_AWS=0
SKIP_SCHEMA=0
REMOTE_DB=""
TARGET_DB=""
COLLATION_NAME=""
CHARACTER_SET=""
FROM_DSN=""
DEFAULT_FROM_DSN="default.remote"
TARGET_DSN="default.local"
TIMEFORMAT='time spent : %3R'
# jscpd:ignore-start
DB_IMPORT_DUMP_DIR=${DB_IMPORT_DUMP_DIR%/}
PROFILES_DIR="$(cd "${CURRENT_DIR}/.." && pwd -P)/conf/dbImportProfiles"
HOME_PROFILES_DIR="${HOME}/.bash-tools/dbImportProfiles"

showHelp() {
  local profilesList=""
  local dsnList=""
  dsnList="$(Conf::getMergedList "dsn" "env")"
  profilesList="$(Conf::getMergedList "dbImportProfiles" "sh" || true)"

  cat <<EOF
${__HELP_TITLE}Description:${__HELP_NORMAL} Import source db into target db

${__HELP_TITLE}Usage:${__HELP_NORMAL} ${SCRIPT_NAME} --help prints this help and exits
${__HELP_TITLE}Usage:${__HELP_NORMAL} ${SCRIPT_NAME} <fromDbName> [<targetDbName>]
${__HELP_TITLE}Usage:${__HELP_NORMAL} ${SCRIPT_NAME} -a|--from-aws <fromDbS3Filename> [<targetDbName>]
                        [-a|--from-aws]
                        [-s|--skip-schema] [-p|--profile profileName]
                        [-o|--collation-name utf8_general_ci] [-c|--character-set utf8]
                        [-t|--target-dsn dsn] [-f|--from-dsn dsn]
                        [--tables tableName1,tableName2]

    <fromDbS3Filename>         If option -a is provided
        remoteDBName will represent the name of the s3 file
        Only .gz or tar.gz file are supported
    <fromDbName>               the name of the source/remote database
    <targetDbName>             the name of the target database, use fromDbName(without extension) if not provided
    -s|--skip-schema            avoid to import the schema
    -o|--collation-name         change the collation name used during database creation
        (default value: collation name used by remote db)
    -c|--character-set          change the character set used during database creation
        (default value: character set used by remote db or dump file if aws)
    -p|--profile profileName    the name of the profile to use in order to include or exclude tables
        (if not specified ${HOME_PROFILES_DIR}/default.sh is used if exists otherwise ${PROFILES_DIR}/default.sh)
    -t|--target-dsn dsn         dsn to use for target database (Default: ${TARGET_DSN})
    -f|--from-dsn dsn           dsn to use for source database (Default: ${DEFAULT_FROM_DSN})
        this option is incompatible with -a|--from-aws option
    -a|--from-aws               db dump will be downloaded from s3 instead of using remote db,
        remoteDBName will represent the name of the file
        profile will be calculated against the dump itself
        this option is incompatible with -f|--from-dsn option
    --tables table1,table2      import only table specified in the list
        if aws mode, ignore profile option

    Aws s3 location       : ${S3_BASE_URL}

${__HELP_TITLE}List of available profiles (default profiles dir ${PROFILES_DIR} can be overridden in home profiles ${HOME_PROFILES_DIR}):${__HELP_NORMAL}
${profilesList}
${__HELP_TITLE}List of available dsn:${__HELP_NORMAL}
${dsnList}

${__HELP_TITLE}Author:${__HELP_NORMAL}
[François Chastanet](https://github.com/fchastanet)

${__HELP_TITLE}Source file:${__HELP_NORMAL}
https://github.com/fchastanet/bash-tools/tree/master/src/_binaries/DbImport/dbImport.sh

${__HELP_TITLE}License:${__HELP_NORMAL}
MIT License

Copyright (c) 2022 François Chastanet
EOF
}
# jscpd:ignore-end

# read command parameters
# $@ is all command line parameters passed to the script.
# -o is for short options like -h
# -l is for long options with double dash like --help
# the comma separates different long options
options=$(getopt -l help,tables:,target-dsn:,from-dsn:,from-aws,skip-schema,profile:,collation-name:,character-set: -o aht:f:sp:c:o: -- "$@" 2>/dev/null) || {
  showHelp
  Log::fatal "invalid options specified"
}

eval set -- "${options}"
while true; do
  case $1 in
    -h | --help)
      showHelp
      exit 0
      ;;
    -a | --from-aws)
      FROM_AWS="1"
      # structure is included in s3 file
      SKIP_SCHEMA="1"
      ;;
    --tables)
      shift || true
      TABLES="$1"
      ;;
    -t | --target-dsn)
      shift || true
      TARGET_DSN="$1"
      ;;
    -f | --from-dsn)
      shift || true
      FROM_DSN="${1:-${DEFAULT_FROM_DSN}}"
      ;;
    -s | --skip-schema)
      SKIP_SCHEMA="1"
      ;;
    -p | --profile)
      shift || true
      PROFILE="$1"
      ;;
    -o | --collation-name)
      shift || true
      COLLATION_NAME="$1"
      ;;
    -c | --character-set)
      shift || true
      CHARACTER_SET="$1"
      ;;
    --)
      shift || true
      break
      ;;
    *)
      showHelp
      Log::fatal "invalid argument $1"
      ;;
  esac
  shift || true
done

# check dependencies
Assert::commandExists mysql "sudo apt-get install -y mysql-client"
Assert::commandExists mysqlshow "sudo apt-get install -y mysql-client"
Assert::commandExists mysqldump "sudo apt-get install -y mysql-client"
Assert::commandExists pv "sudo apt-get install -y pv"
Assert::commandExists gawk "sudo apt-get install -y gawk"
Assert::commandExists awk "sudo apt-get install -y gawk"
Version::checkMinimal "gawk" "--version" "5.0.1"

# additional arguments
shift $((OPTIND - 1)) || true
while true; do
  if [[ -z "$1" ]]; then
    # last argument
    break
  fi
  if [[ -z "${REMOTE_DB}" ]]; then
    REMOTE_DB="$1"
  else
    TARGET_DB="$1"
  fi
  shift || true
done

if [[ -z "${REMOTE_DB}" ]]; then
  Log::fatal "you must provide remoteDbName"
fi

if [[ -z "${TARGET_DB}" ]]; then
  # remove eventual file extension
  TARGET_DB="${REMOTE_DB%%.*}"
fi

# check s3 parameter
if [[ "${FROM_AWS}" = "1" ]]; then
  Assert::commandExists aws \
    "missing aws, please check https://docs.aws.amazon.com/fr_fr/cli/latest/userguide/install-cliv2.html" || exit 1

  if [[ -n "${FROM_DSN}" ]]; then
    Log::fatal "you cannot use from-dsn and from-aws at the same time"
  fi

  if [[ -z "${S3_BASE_URL}" ]]; then
    Log::fatal "missing S3_BASE_URL, please provide a value in .env file"
  fi
elif [[ -z "${FROM_DSN}" ]]; then
  # default value for FROM_DSN if from-aws not set
  FROM_DSN="${DEFAULT_FROM_DSN}"
fi

# load the profile
if [[ -z "${PROFILE}" ]]; then
  showHelp
  Log::fatal "you should specify a profile"
fi

[[ "${PROFILE}" != "default" && -n "${TABLES}" ]] &&
  Log::fatal "you cannot use table and profile options at the same time"

# Profile selection
PROFILE_COMMAND="$(Conf::getAbsoluteFile "dbImportProfiles" "${PROFILE}" "sh")" || exit 1
PROFILE_MSG_INFO="Using profile ${PROFILE_COMMAND}"
if [[ -n "${TABLES}" ]]; then
  [[ ${TABLES} =~ ^[A-Za-z0-9_]+(,[A-Za-z0-9_]+)*$ ]] || {
    Log::fatal "Table list is not valid : ${TABLES}"
  }
fi

if [[ "${PROFILE}" = 'default' && -n "${TABLES}" ]]; then
  PROFILE_COMMAND=$(Framework::createTempFile "profileCmd.XXXXXXXXXXXX")
  chmod +x "${PROFILE_COMMAND}"
  PROFILE_MSG_INFO="only ${TABLES} will be imported"
  (
    echo '#!/usr/bin/env bash'
    if [[ -n "${TABLES}" ]]; then
      echo "${TABLES}" | sed -E 's/([A-Za-z0-9_]+),?/echo "\1"\n/g'
    else
      # tables option not specified, we will import all tables of the profile
      echo 'cat'
    fi
  ) >"${PROFILE_COMMAND}"
fi
Log::displayInfo "${PROFILE_MSG_INFO}"

[[ -z "${DB_IMPORT_DUMP_DIR}" ]] &&
  Log::fatal "you have to specify a value for DB_IMPORT_DUMP_DIR env variable"

if [[ ! -d "${DB_IMPORT_DUMP_DIR}" ]]; then
  mkdir -p "${DB_IMPORT_DUMP_DIR}" ||
    Log::fatal "impossible to create directory ${DB_IMPORT_DUMP_DIR} specified by DB_IMPORT_DUMP_DIR env variable"
fi

# create db instances
declare -Agx dbFromInstance dbTargetDatabase

Database::newInstance dbTargetDatabase "${TARGET_DSN}"
Database::setQueryOptions dbTargetDatabase "${dbTargetDatabase[QUERY_OPTIONS]} --connect-timeout=5"
Log::displayInfo "Using target dsn ${dbTargetDatabase['DSN_FILE']}"
if [[ "${FROM_AWS}" = "0" ]]; then
  Database::newInstance dbFromInstance "${FROM_DSN}"
  Database::setQueryOptions dbFromInstance "${dbFromInstance[QUERY_OPTIONS]} --connect-timeout=5"
  Log::displayInfo "Using from dsn ${dbFromInstance['DSN_FILE']}"
fi

if [[ "${FROM_AWS}" = "1" ]]; then
  REMOTE_DB_DUMP_TEMP_FILE="${DB_IMPORT_DUMP_DIR}/${REMOTE_DB}"
else
  REMOTE_DB_DUMP_TEMP_FILE="${DB_IMPORT_DUMP_DIR}/${REMOTE_DB}_${PROFILE}.sql.gz"
  REMOTE_DB_STRUCTURE_DUMP_TEMP_FILE="${DB_IMPORT_DUMP_DIR}/${REMOTE_DB}_${PROFILE}_structure.sql.gz"
fi

# check if local dump exists
if [[ ! -f "${REMOTE_DB_DUMP_TEMP_FILE}" ]]; then
  Log::displayInfo "local dump does not exist"
  DOWNLOAD_DUMP=1
fi
if [[ "${FROM_AWS}" = "0" && ! -f "${REMOTE_DB_STRUCTURE_DUMP_TEMP_FILE}" ]]; then
  Log::displayInfo "local structure dump does not exist"
  DOWNLOAD_DUMP=1
fi
if [[ "${DOWNLOAD_DUMP}" = "0" ]]; then
  Log::displayInfo "local dump ${REMOTE_DB_DUMP_TEMP_FILE} already exists, avoid download"
fi

# dump header/footer
read -r -d '\0' DUMP_HEADER <<-EOM
    SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS = 0;
    SET @OLD_AUTOCOMMIT=@@AUTOCOMMIT, AUTOCOMMIT = 0;
    SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS = 0;\0
EOM

read -r -d '\0' DUMP_FOOTER <<-EOM2
    COMMIT;
    SET AUTOCOMMIT=@OLD_AUTOCOMMIT;
    SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS;
    SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS;\0
EOM2

Log::displayInfo "tables list will calculated using profile ${PROFILE} => ${PROFILE_COMMAND}"
chmod +x "${PROFILE_COMMAND}"
SECONDS=0
if [[ "${DOWNLOAD_DUMP}" = "1" ]]; then
  Log::displayInfo "Download dump"

  if [[ "${FROM_AWS}" = "1" ]]; then
    # download dump from s3
    S3_URL="${S3_BASE_URL%/}/${REMOTE_DB}"
    aws s3 ls --human-readable "${S3_URL}" || {
      Log::fatal "unable to get information on S3 object : ${S3_URL}"
    }
    Log::displayInfo "Download dump from ${S3_URL} ..."
    TMPDIR="${TMDIR:-/tmp}" aws s3 cp "${S3_URL}" "${REMOTE_DB_DUMP_TEMP_FILE}" || {
      Log::fatal "unable to download dump from S3 : ${S3_URL}"
    }
  else
    # check if remote db exists
    Database::ifDbExists dbFromInstance "${REMOTE_DB}" || {
      Log::fatal "Remote Database ${REMOTE_DB} does not exist"
    }

    # get remote db collation name
    if [[ -z "${COLLATION_NAME}" ]]; then
      COLLATION_NAME=$(Database::query dbFromInstance \
        "SELECT default_collation_name FROM information_schema.SCHEMATA WHERE schema_name = \"${REMOTE_DB}\";" "information_schema")
    fi

    # get remote db character set
    if [[ -z "${CHARACTER_SET}" ]]; then
      CHARACTER_SET=$(Database::query dbFromInstance \
        "SELECT default_character_set_name FROM information_schema.SCHEMATA WHERE schema_name = \"${REMOTE_DB}\";" "information_schema")
    fi

    DUMP_HEADER=$(printf "%s\nSET names '%s';\n" "${DUMP_HEADER}" "${CHARACTER_SET}")

    # calculate remote db dump size
    LIST_TABLES="$(Database::query dbFromInstance "show tables" "${REMOTE_DB}" | ${PROFILE_COMMAND} | sort)"
    LIST_TABLES_DUMP_SIZE="$(echo "${LIST_TABLES}" | awk -v d="," -v q="'" '{s=(NR==1?s:s d)q $0 q}END{print s }')"
    LIST_TABLES_DUMP=$(echo "${LIST_TABLES}" | awk -v d=" " -v q="" '{s=(NR==1?s:s d)q $0 q}END{print s }')
    Log::displayInfo "Calculate dump size for tables ${LIST_TABLES_DUMP}"
    DUMP_SIZE_QUERY="SELECT ROUND(SUM(data_length + index_length) / 1024 / 1024, 0) AS size FROM information_schema.TABLES WHERE table_schema=\"${REMOTE_DB}\""
    DUMP_SIZE_QUERY+=" AND table_name IN(${LIST_TABLES_DUMP_SIZE}, 'dummy') "
    DUMP_SIZE_QUERY+=" GROUP BY table_schema"
    REMOTE_DB_DUMP_SIZE=$(echo "${DUMP_SIZE_QUERY}" | Database::query dbFromInstance)
    if [[ -z "${REMOTE_DB_DUMP_SIZE}" ]]; then
      # could occur with the none profile
      REMOTE_DB_DUMP_SIZE="0"
    fi

    # dump db
    Log::displayInfo "Dump the database ${REMOTE_DB} (Size:${REMOTE_DB_DUMP_SIZE}MB) ..."
    DUMP_SIZE_PV_ESTIMATION=$(awk "BEGIN {printf \"%.0f\",${REMOTE_DB_DUMP_SIZE}/1.5}")
    time (
      echo "${DUMP_HEADER}"
      Database::dump dbFromInstance "${REMOTE_DB}" "${LIST_TABLES_DUMP}" \
        --no-create-info --skip-add-drop-table --single-transaction=TRUE |
        pv --progress --size "${DUMP_SIZE_PV_ESTIMATION}m"
      echo "${DUMP_FOOTER}"
    ) | gzip >"${REMOTE_DB_DUMP_TEMP_FILE}"

    Log::displayInfo "Dump structure of the database ${REMOTE_DB} ..."
    time (
      echo "${DUMP_HEADER}"
      #shellcheck disable=SC2016
      Database::dump dbFromInstance "${REMOTE_DB}" "" \
        --no-data --skip-add-drop-table --single-transaction=TRUE |
        sed 's/^CREATE TABLE `/CREATE TABLE IF NOT EXISTS `/g'
      echo "${DUMP_FOOTER}"
    ) | gzip >"${REMOTE_DB_STRUCTURE_DUMP_TEMP_FILE}"
  fi
  Log::displayInfo "Dump done."
fi

# mark dumps as modified now to avoid them to be garbage collected
touch -c -m "${REMOTE_DB_DUMP_TEMP_FILE}" || true
touch -c -m "${REMOTE_DB_STRUCTURE_DUMP_TEMP_FILE}" || true

# TODO Collation and character set should be retrieved from dump files if possible
COLLATION_NAME="${COLLATION_NAME:-utf8_general_ci}"
CHARACTER_SET="${CHARACTER_SET:-utf8}"

Log::displayInfo "create target database ${TARGET_DB} if needed"
#shellcheck disable=SC2016
Database::query dbTargetDatabase \
  "$(printf 'CREATE DATABASE IF NOT EXISTS `%s` CHARACTER SET "%s" COLLATE "%s"' "${TARGET_DB}" "${CHARACTER_SET}" "${COLLATION_NAME}")"

if [[ "${FROM_AWS}" = "1" ]]; then
  "${CURRENT_DIR}/dbImportStream" \
    "${REMOTE_DB_DUMP_TEMP_FILE}" \
    "${TARGET_DB}" \
    "${PROFILE_COMMAND}" \
    "${dbTargetDatabase['AUTH_FILE']}" \
    "${CHARACTER_SET}" \
    "${dbTargetDatabase['DB_IMPORT_OPTIONS']}"
else
  Database::setQueryOptions dbTargetDatabase "${dbTargetDatabase['DB_IMPORT_OPTIONS']}"
  Log::displayInfo "Importing remote db '${REMOTE_DB}' to local db '${TARGET_DB}'"
  if [[ "${SKIP_SCHEMA}" = "1" ]]; then
    Log::displayInfo "avoid to create db structure"
  else
    Log::displayInfo "create db structure from ${REMOTE_DB_STRUCTURE_DUMP_TEMP_FILE}"
    time (
      pv "${REMOTE_DB_STRUCTURE_DUMP_TEMP_FILE}" | zcat |
        Database::query dbTargetDatabase "" "${TARGET_DB}"
    )
  fi

  Log::displayInfo "import remote to local from file ${REMOTE_DB_DUMP_TEMP_FILE}"
  time (
    "${CURRENT_DIR}/dbImportStream" \
      "${REMOTE_DB_DUMP_TEMP_FILE}" \
      "${TARGET_DB}" \
      "${PROFILE_COMMAND}" \
      "${dbTargetDatabase['AUTH_FILE']}" \
      "${CHARACTER_SET}" \
      "${dbTargetDatabase['DB_IMPORT_OPTIONS']}"
  )
fi

# garbage collect db import dumps
File::garbageCollect "${DB_IMPORT_DUMP_DIR}" "${DB_IMPORT_GARBAGE_COLLECT_DAYS:-+30}" || true

Log::displayInfo "Import database duration : $(date -u -d "@${SECONDS}" +"%T")"
